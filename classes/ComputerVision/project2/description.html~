<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/1999/REC-html401-19991224/loose.dtd"> 
<html> 
  <head> 
    <title> 
    robert pless - Computer Vision - Project 2
    </title> 
    <meta name="keywords" content="robert pless, computer vision course notes"> 
     <link rel="STYLESHEET" href="../mystyle.css" type="text/css">   
  </head> 
  <body> 

<body>
<img src="lynx_ssd.jpg" alt="Teaser Image" height="200" width="900" align="center" /> <br>
<h3> Project 2: Hybrid Images</h3>


<h3>Overview</h3>

<p class="text">The goal of this part of the assignment is to create <a
href="http://cvcl.mit.edu/hybridimage/">hybrid images</a> using the approach
described in the SIGGRAPH 2006 <a
href="http://cvcl.mit.edu/publications/OlivaTorralb_Hybrid_Siggraph06.pdf">paper</a>
by Oliva, Torralba, and Schyns. <i>Hybrid images</i> are static images that
change in interpretation as a function of the viewing distance. The basic idea is that high frequency tends
to dominate perception when it is available, but, at a distance, only the low
frequency (smooth) part of the signal can be seen. By blending the high frequency portion of one image with the low-frequency portion of another, you get a hybrid image that leads to different interpretations at different distances.
</p>

<h3>Details</h3>

<p class=text><a href="./hybrid.zip">Here</a>, we have included two sample images (of Derek and his former cat Nutmeg) and  some matlab
starter code that can be used to load two images and align them. <a href="./hybrid_python.zip">Here</a> is the python version. The alignment is important because it affects
the perceptual grouping (read the paper for details).</p>

<ol>
  <li>
    First, you'll need to get a few pairs of images that you want to make into
    hybrid images.  You can use the sample
    images for debugging, but you should use your own images in your results.  Then, you will need to write code to low-pass
    filter one image, high-pass filter the second image, and add (or average) the
    two images.  For a low-pass filter, Oliva et al. suggest using a standard 2D Gaussian filter. For a high-pass filter, they suggest using
    the impulse filter minus the Gaussian filter (which can be computed by subtracting the Gaussian-filtered image from the original). 
    The <a
href="http://en.wikipedia.org/wiki/Cutoff_frequency">cutoff-frequency</a> of
    each filter should be chosen with some experimentation.</li>
  <li>For your favorite result, you should also illustrate the process through frequency analysis.  Show the log magnitude of the Fourier transform of the two input images, the filtered images, and the
    hybrid image.  In MATLAB, you can compute and display the 2D Fourier transform with
    with: 
  <span style='font-size:11.0pt;font-family:"Courier New"'>imagesc(log(abs(fftshift(fft2(gray_image)))))</span>and in Python it's <span style='font-size:11.0pt;font-family:"Courier New"'>plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(gray_image)))))</span> </li>
  <li>Try creating a variety of types of hybrid images (change of expression,
    morph between different objects, change over time, etc.).
    The <a href="http://cvcl.mit.edu/hybridimage/">site</a> has several examples that
    may inspire.</li>
</ol>
<h3> Bells &amp; Whistles (Extra Points)</h3>

<p class=text>Try using color to enhance the effect.
Does it work better to use color for the high-frequency component, the
low-frequency component, or both? (5 pts)


</div>

